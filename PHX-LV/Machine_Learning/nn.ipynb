{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:27:16.669797Z",
     "start_time": "2024-04-07T05:27:16.380153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"output.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert 'Date' column to datetime type\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# # Subtract 30 days from each date\n",
    "# df['Date'] = df['Date'] - pd.Timedelta(days=30)\n",
    "\n",
    "# # Output the updated DataFrame\n",
    "# print(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi and average delay Takeoff Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define a function to extract the numeric part from the string\n",
    "def extract_numeric(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to clean the \"Taxi Landing\" column\n",
    "df['Taxi Landing'] = df['Taxi Landing'].apply(extract_numeric)\n",
    "df['Taxi Takeoff'] = df['Taxi Takeoff'].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeoff Conversion from 12 hours format to 24 hours format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time-related columns\n",
    "time_columns = ['Gate Departure Actual', 'Gate Departure Estimated', 'Takeoff Actual', 'Takeoff Estimated', 'Gate Arrival Actual', 'Gate Arrival Estimated', 'Landing Actual', 'Landing Estimated']\n",
    "\n",
    "# Replace non-time values ('--') with NaN\n",
    "df[time_columns] = df[time_columns].replace('--', pd.NA)\n",
    "\n",
    "# Convert time columns to 24-hour format\n",
    "for column in time_columns:\n",
    "    # Convert to datetime objects\n",
    "    df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "    # Convert to 24-hour format\n",
    "    df[column] = df[column].dt.strftime('%H:%M')\n",
    "\n",
    "# Display the DataFrame after conversion\n",
    "# print(df[time_columns])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['Takeoff Actual', 'Takeoff Estimated', 'Landing Actual','Landing Estimated']\n",
    "target = 'Landing Actual'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert time columns to numerical format (hours and minutes)\n",
    "for column in ['Takeoff Actual', 'Takeoff Estimated', 'Landing Actual', 'Landing Estimated']:\n",
    "    df[column] = pd.to_datetime(df[column]).dt.hour * 60 + pd.to_datetime(df[column]).dt.minute\n",
    "\n",
    "# Define a function to map categories to numerical values\n",
    "def map_delay_to_numeric(text):\n",
    "    if 'Less than 10 minutes' in text:\n",
    "        return 0\n",
    "    elif '10-20 minutes' in text:\n",
    "        return 1\n",
    "    elif '20-40 minutes' in text:\n",
    "        return 2\n",
    "    elif '40 minutes - 1 hour' in text:\n",
    "        return 3\n",
    "    elif 'More than 1 hour' in text:\n",
    "        return 4\n",
    "    else:\n",
    "        return -1  # Handle unknown cases if any\n",
    "\n",
    "# Convert all values in 'Average Delay Takeoff' column to strings\n",
    "df['Average Delay Takeoff'] = df['Average Delay Takeoff'].astype(str)\n",
    "\n",
    "# Apply the mapping function to convert categories to numerical values\n",
    "df['Average Delay Takeoff Numeric'] = df['Average Delay Takeoff'].apply(map_delay_to_numeric)\n",
    "\n",
    "# Define features and target\n",
    "features = ['Takeoff Actual', 'Takeoff Estimated', 'Landing Estimated', 'Average Delay Takeoff Numeric']\n",
    "target = 'Landing Actual'\n",
    "\n",
    "# Extract features and target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the first few rows of the modified DataFrame\n",
    "print(df[['Average Delay Takeoff', 'Average Delay Takeoff Numeric']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the correct number of input features\n",
    "num_input_features = X_train_tensor.shape[1]\n",
    "\n",
    "# Define neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_input_features, 64)  # Input layer\n",
    "        self.fc2 = nn.Linear(64, 32)                  # Hidden layer\n",
    "        self.fc3 = nn.Linear(32, 1)                   # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function to first layer\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function to second layer\n",
    "        x = self.fc3(x)              # Output layer (no activation function)\n",
    "        return x\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def __str__(self):      # The toString method for the class\n",
    "        return \"<CNN Initialized>\"\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def predict(self, take_off_actual: int, take_off_estimated: int, landing_estimated: int, average_delay: int):\n",
    "        data = [x if x is not None else 0 for x in [take_off_actual, take_off_estimated, landing_estimated, average_delay]]\n",
    "        new_data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        predicted_arrival_time_tensor = self.forward(new_data_tensor)\n",
    "        predicted_arrival_time = predicted_arrival_time_tensor.item()\n",
    "\n",
    "        return predicted_arrival_time\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = NeuralNetwork()\n",
    "# Make predictions on the training data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train_tensor = model(X_train_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining loss function and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 632.3597\n",
      "Epoch [200/10000], Loss: 607.0744\n",
      "Epoch [300/10000], Loss: 555.1799\n",
      "Epoch [400/10000], Loss: 450.5460\n",
      "Epoch [500/10000], Loss: 367.2429\n",
      "Epoch [600/10000], Loss: 295.4038\n",
      "Epoch [700/10000], Loss: 235.6889\n",
      "Epoch [800/10000], Loss: 189.3632\n",
      "Epoch [900/10000], Loss: 156.1434\n",
      "Epoch [1000/10000], Loss: 134.2830\n",
      "Epoch [1100/10000], Loss: 120.8329\n",
      "Epoch [1200/10000], Loss: 112.5780\n",
      "Epoch [1300/10000], Loss: 107.3254\n",
      "Epoch [1400/10000], Loss: 103.2598\n",
      "Epoch [1500/10000], Loss: 99.6011\n",
      "Epoch [1600/10000], Loss: 96.1180\n",
      "Epoch [1700/10000], Loss: 92.5580\n",
      "Epoch [1800/10000], Loss: 88.1640\n",
      "Epoch [1900/10000], Loss: 83.3972\n",
      "Epoch [2000/10000], Loss: 78.2502\n",
      "Epoch [2100/10000], Loss: 72.7750\n",
      "Epoch [2200/10000], Loss: 66.2138\n",
      "Epoch [2300/10000], Loss: 59.5208\n",
      "Epoch [2400/10000], Loss: 52.1535\n",
      "Epoch [2500/10000], Loss: 45.3245\n",
      "Epoch [2600/10000], Loss: 39.2853\n",
      "Epoch [2700/10000], Loss: 34.1128\n",
      "Epoch [2800/10000], Loss: 29.7871\n",
      "Epoch [2900/10000], Loss: 26.2867\n",
      "Epoch [3000/10000], Loss: 23.5436\n",
      "Epoch [3100/10000], Loss: 21.4632\n",
      "Epoch [3200/10000], Loss: 19.9341\n",
      "Epoch [3300/10000], Loss: 18.8385\n",
      "Epoch [3400/10000], Loss: 18.0681\n",
      "Epoch [3500/10000], Loss: 17.5332\n",
      "Epoch [3600/10000], Loss: 17.1632\n",
      "Epoch [3700/10000], Loss: 16.9048\n",
      "Epoch [3800/10000], Loss: 16.7235\n",
      "Epoch [3900/10000], Loss: 16.5951\n",
      "Epoch [4000/10000], Loss: 16.4997\n",
      "Epoch [4100/10000], Loss: 16.4328\n",
      "Epoch [4200/10000], Loss: 16.3905\n",
      "Epoch [4300/10000], Loss: 16.3765\n",
      "Epoch [4400/10000], Loss: 16.3110\n",
      "Epoch [4500/10000], Loss: 16.2827\n",
      "Epoch [4600/10000], Loss: 16.2264\n",
      "Epoch [4700/10000], Loss: 16.2084\n",
      "Epoch [4800/10000], Loss: 16.1735\n",
      "Epoch [4900/10000], Loss: 16.1842\n",
      "Epoch [5000/10000], Loss: 16.1136\n",
      "Epoch [5100/10000], Loss: 16.0779\n",
      "Epoch [5200/10000], Loss: 16.0507\n",
      "Epoch [5300/10000], Loss: 16.0315\n",
      "Epoch [5400/10000], Loss: 15.9858\n",
      "Epoch [5500/10000], Loss: 15.9546\n",
      "Epoch [5600/10000], Loss: 15.9213\n",
      "Epoch [5700/10000], Loss: 15.8868\n",
      "Epoch [5800/10000], Loss: 15.8770\n",
      "Epoch [5900/10000], Loss: 15.8364\n",
      "Epoch [6000/10000], Loss: 15.7861\n",
      "Epoch [6100/10000], Loss: 15.7902\n",
      "Epoch [6200/10000], Loss: 15.7113\n",
      "Epoch [6300/10000], Loss: 15.6545\n",
      "Epoch [6400/10000], Loss: 15.6797\n",
      "Epoch [6500/10000], Loss: 15.6039\n",
      "Epoch [6600/10000], Loss: 15.5384\n",
      "Epoch [6700/10000], Loss: 15.5552\n",
      "Epoch [6800/10000], Loss: 15.4431\n",
      "Epoch [6900/10000], Loss: 15.4212\n",
      "Epoch [7000/10000], Loss: 15.4895\n",
      "Epoch [7100/10000], Loss: 15.3996\n",
      "Epoch [7200/10000], Loss: 15.4274\n",
      "Epoch [7300/10000], Loss: 15.3710\n",
      "Epoch [7400/10000], Loss: 15.1838\n",
      "Epoch [7500/10000], Loss: 15.3974\n",
      "Epoch [7600/10000], Loss: 15.3147\n",
      "Epoch [7700/10000], Loss: 15.3253\n",
      "Epoch [7800/10000], Loss: 15.2412\n",
      "Epoch [7900/10000], Loss: 15.2246\n",
      "Epoch [8000/10000], Loss: 14.9319\n",
      "Epoch [8100/10000], Loss: 15.0722\n",
      "Epoch [8200/10000], Loss: 14.8938\n",
      "Epoch [8300/10000], Loss: 15.0659\n",
      "Epoch [8400/10000], Loss: 15.1455\n",
      "Epoch [8500/10000], Loss: 14.8948\n",
      "Epoch [8600/10000], Loss: 14.7115\n",
      "Epoch [8700/10000], Loss: 14.6313\n",
      "Epoch [8800/10000], Loss: 15.5802\n",
      "Epoch [8900/10000], Loss: 17.9683\n",
      "Epoch [9000/10000], Loss: 15.0266\n",
      "Epoch [9100/10000], Loss: 16.3475\n",
      "Epoch [9200/10000], Loss: 15.9030\n",
      "Epoch [9300/10000], Loss: 15.1088\n",
      "Epoch [9400/10000], Loss: 14.6046\n",
      "Epoch [9500/10000], Loss: 16.4889\n",
      "Epoch [9600/10000], Loss: 14.4033\n",
      "Epoch [9700/10000], Loss: 18.1417\n",
      "Epoch [9800/10000], Loss: 14.7527\n",
      "Epoch [9900/10000], Loss: 14.4150\n",
      "Epoch [10000/10000], Loss: 16.7287\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10000\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 16.2938\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    mse = criterion(y_pred_tensor, y_test_tensor)\n",
    "    print(f'Mean Squared Error on Test Data: {mse.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[features].corr(), annot=True, cmap='Blues')\n",
    "plt.title(\"Correlation of Features\")\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs. predicted values for training data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_train_tensor, model(X_train_tensor).detach().numpy(), color='blue', alpha=0.5, label='Training Values')\n",
    "plt.plot([min(y_train_tensor), max(y_train_tensor)], [min(y_train_tensor), max(y_train_tensor)], linestyle='--', color='blue')  # Diagonal line\n",
    "plt.xlabel(\"Actual Time of Arrival (Training)\")\n",
    "plt.ylabel(\"Predicted Time of Arrival (Training)\")\n",
    "plt.title(\"Actual vs. Predicted Time of Arrival (Neural Network - Training)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs. predicted values for test data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_tensor, y_pred_tensor.numpy(), color='green', alpha=0.5)\n",
    "plt.plot([min(y_test_tensor), max(y_test_tensor)], [min(y_test_tensor), max(y_test_tensor)], linestyle='--', color='red')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values (Neural Network - Test)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the absolute difference between actual and estimated time of arrival\n",
    "arrival_time_difference = torch.abs(y_test_tensor - y_pred_tensor).numpy()\n",
    "\n",
    "# Visualize the difference\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(arrival_time_difference, bins=10, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Absolute Difference between Actual and Estimated Time of Arrival')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Arrival Time Differences')\n",
    "plt.show()\n",
    "\n",
    "# Analyze the difference\n",
    "mean_difference = arrival_time_difference.mean()\n",
    "max_difference = arrival_time_difference.max()\n",
    "min_difference = arrival_time_difference.min()\n",
    "\n",
    "print(\"Mean difference:\", mean_difference)\n",
    "print(\"Maximum difference:\", max_difference)\n",
    "print(\"Minimum difference:\", min_difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Convert predicted values to numpy arrays\n",
    "y_pred_train = model(X_train_tensor).detach().numpy().reshape(-1)\n",
    "y_pred_test = model(X_test_tensor).detach().numpy().reshape(-1)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and Mean Absolute Error (MAE) for training and test data\n",
    "mse_train = mean_squared_error(y_train_tensor, torch.tensor(y_pred_train, dtype=torch.float32))\n",
    "mae_train = mean_absolute_error(y_train_tensor, torch.tensor(y_pred_train, dtype=torch.float32))\n",
    "mse_test = mean_squared_error(y_test_tensor, torch.tensor(y_pred_test, dtype=torch.float32))\n",
    "mae_test = mean_absolute_error(y_test_tensor, torch.tensor(y_pred_test, dtype=torch.float32))\n",
    "\n",
    "print(\"Mean Squared Error (MSE) - Train:\", mse_train)\n",
    "print(\"Mean Absolute Error (MAE) - Train:\", mae_train)\n",
    "print(\"Mean Squared Error (MSE) - Test:\", mse_test)\n",
    "print(\"Mean Absolute Error (MAE) - Test:\", mae_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_log_error, explained_variance_score\n",
    "\n",
    "# R² Score (coefficient of determination) = 1 - (SS_res / SS_tot)\n",
    "# Measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "r2_train = r2_score(y_train_tensor, y_pred_train_tensor)\n",
    "r2_test = r2_score(y_test_tensor, y_pred_tensor)\n",
    "\n",
    "# MAPE = (1/n) * Σ(|actual - predicted| / |actual|) * 100%\n",
    "# Calculates the mean of the absolute percentage errors between the predicted and actual values \n",
    "mape_train = mean_absolute_percentage_error(y_train_tensor, y_pred_train_tensor)\n",
    "mape_test = mean_absolute_percentage_error(y_test_tensor, y_pred_tensor)\n",
    "\n",
    "# Clip negative values to zero\n",
    "y_train_tensor_clipped = np.clip(y_train_tensor, 0, None)\n",
    "y_pred_train_tensor_clipped = np.clip(y_pred_train_tensor, 0, None)\n",
    "y_test_tensor_clipped = np.clip(y_test_tensor, 0, None)\n",
    "y_pred_tensor_clipped = np.clip(y_pred_tensor, 0, None)\n",
    "\n",
    "# Calculate RMSLE with clipped targets\n",
    "rmsle_train = np.sqrt(mean_squared_log_error(y_train_tensor_clipped, y_pred_train_tensor_clipped))\n",
    "rmsle_test = np.sqrt(mean_squared_log_error(y_test_tensor_clipped, y_pred_tensor_clipped))\n",
    "\n",
    "# Calculate Explained Variance Score = 1 - (Var(y_true - y_pred) / Var(y_true))\n",
    "# Explained Variance Score measures the proportion to which a mathematical model accounts for the variation (dispersion) of a given data set.\n",
    "explained_variance_train = explained_variance_score(y_train_tensor, y_pred_train_tensor)\n",
    "explained_variance_test = explained_variance_score(y_test_tensor, y_pred_tensor)\n",
    "\n",
    "print(\"R² Score (Train):\", r2_train)\n",
    "print(\"R² Score (Test):\", r2_test)\n",
    "print(\"MAPE (Train):\", mape_train)\n",
    "print(\"MAPE (Test):\", mape_test)\n",
    "print(\"RMSLE (Train):\", rmsle_train)\n",
    "print(\"RMSLE (Test):\", rmsle_test)\n",
    "print(\"Explained Variance Score (Train):\", explained_variance_train)\n",
    "print(\"Explained Variance Score (Test):\", explained_variance_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression to avoid Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize Ridge and Lasso regression models\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha parameter for regularization strength\n",
    "\n",
    "# Train Ridge and Lasso models\n",
    "ridge_model.fit(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ridge_train = ridge_model.predict(X_train_tensor)\n",
    "y_pred_ridge_test = ridge_model.predict(X_test_tensor)\n",
    "\n",
    "\n",
    "# Evaluate the models\n",
    "mse_ridge_train = mean_squared_error(y_train_tensor, y_pred_ridge_train)\n",
    "mse_ridge_test = mean_squared_error(y_test_tensor, y_pred_ridge_test)\n",
    "\n",
    "\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"Train MSE:\", mse_ridge_train)\n",
    "print(\"Test MSE:\", mse_ridge_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogram: Distribution of taxi landing time with bigger bins\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['Taxi Landing'], bins=50, color='skyblue', edgecolor='black', kde=True)\n",
    "plt.title('Distribution of Taxi Landing Time')\n",
    "plt.xlabel('Taxi Landing Time (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Histogram: Distribution of taxi takeoff time with bigger bins\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['Taxi Takeoff'], bins=50, color='skyblue', edgecolor='black', kde=True)\n",
    "plt.title('Distribution of Taxi Takeoff Time')\n",
    "plt.xlabel('Taxi Takeoff Time (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Average delay landing by flight number\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Flight Number', y='Average Delay Landing', data=df, palette='viridis')\n",
    "plt.title('Average Delay Landing by Flight Number')\n",
    "plt.xlabel('Flight Number')\n",
    "plt.ylabel('Average Delay Landing (minutes)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test_tensor and y_pred_test_tensor are available\n",
    "# Convert tensor values to numpy arrays\n",
    "y_test = y_test_tensor.numpy()\n",
    "y_pred_test = y_pred_tensor.numpy()\n",
    "\n",
    "# Histogram: Distribution of prediction errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(y_test - y_pred_test, bins=20, color='skyblue', edgecolor='black', kde=True)\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the weights of the input layer\n",
    "input_layer_weights = model.fc1.weight.detach().numpy()\n",
    "\n",
    "# Calculate the absolute sum of weights for each feature\n",
    "feature_importance = np.abs(input_layer_weights).sum(axis=0)  # sum along the columns\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = ['Takeoff Actual', 'Takeoff Estimated', 'Landing Estimated', 'Average Delay Takeoff Numeric']\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Actual Time of Arrival using object method: 569.512939453125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample input data for testing\n",
    "sample_input_data = {\n",
    "    'Takeoff Actual': 8 * 60 + 30,  # Takeoff time  (8:30 AM)\n",
    "    'Takeoff Estimated': 8 * 60 + 40,  # Estimated takeoff time (8:40 AM)\n",
    "    'Landing Estimated': 9 * 60 + 50,  # Estimated landing time (9:50 AM)\n",
    "    'Average Delay Takeoff Numeric': 1  # Numeric representation of average delay\n",
    "}\n",
    "# features = ['Takeoff Actual', 'Takeoff Estimated', 'Landing Estimated', 'Average Delay Takeoff Numeric']\n",
    "\n",
    "res = model.predict(8 * 60 + 30, 8 * 60 + 40, 9 * 60 + 50, 1)\n",
    "print(f\"Predicted Actual Time of Arrival using object method: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CNN Initialized>\n"
     ]
    }
   ],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "print(model)\n",
    "scripted_model.save(\"../trained-model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
